{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "TXvPAW81gXAb",
        "ZDB50y8DWSEO",
        "aIY2ROFZWqc2",
        "LdfNnCAMaW9z",
        "djtmIy5DkyEZ",
        "O2su9P7WlYhb",
        "bXWV6MCZyBkL",
        "hgRvDCLgqnyz",
        "ViGv7fLpYH2E",
        "65lExBLzhKtZ",
        "47T9odMGBR2i"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjBKlYSeQwSW"
      },
      "outputs": [],
      "source": [
        "with open('/content/the-verdict.txt','r', encoding=\"utf-8\") as f:\n",
        "    raw_text = f.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ey1h3Y_lkwT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(raw_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4t-2h39Ri3L",
        "outputId": "86a61999-b208-444f-b116-d1de3d776e2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20479\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we want to tokenize this 20479 character that we can later turn into embeddings to LLMs"
      ],
      "metadata": {
        "id": "9N0AEBNwRxlU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# now we will use regular expression Python library to split any given text\n",
        "import re\n",
        "\n",
        "processed = re.split(r'([,.;\":?!_()\\']|--|\\s)', raw_text)\n",
        "processed = [item.strip() for item in processed if item.strip()]"
      ],
      "metadata": {
        "id": "G1UmgoA_R-vD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(processed[:30])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "np9F_Qj5VEGE",
        "outputId": "464849cb-3cd7-4e8c-f53b-266c66171559"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(processed))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxMyPHRAVGzh",
        "outputId": "e7c6761e-1420-4cf0-b666-8e3b30aabffe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4690\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting Tokens into token IDs"
      ],
      "metadata": {
        "id": "W9tSJrc1Vm0h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# now we give token to any id\n",
        "all_words = sorted(set(processed))\n",
        "print(len(all_words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3fU4hT4VpbW",
        "outputId": "33edc420-b60e-4605-d500-90b9a9810018"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1130\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now we assign each word to a unique number\n",
        "vocab = {token:integer for token,integer in enumerate(all_words)}"
      ],
      "metadata": {
        "id": "kXI5ioE1W1TP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleTokenizerV1:\n",
        "    def __init__(self, vocab):\n",
        "        self.str_to_int = vocab\n",
        "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
        "\n",
        "\n",
        "    def encode(self,text):\n",
        "        preprocessed = re.split(r'([,.;:\"()\\'] |--|\\s)',text)\n",
        "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
        "\n",
        "        ids = [self.str_to_int[s] for s in preprocessed]\n",
        "        return ids\n",
        "\n",
        "\n",
        "    def decoder(self, ids):\n",
        "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
        "        text = re.sub(r'\\s+([,.?!\"()\\'])',r'\\1',text)\n",
        "        return text\n"
      ],
      "metadata": {
        "id": "i19M0oocYd4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = SimpleTokenizerV1(vocab)\n"
      ],
      "metadata": {
        "id": "-wEXQiiOcVfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_tokens = sorted(list(set(processed)))\n",
        "all_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
        "\n",
        "vocab = {token:integer for integer,token in enumerate(all_tokens)}"
      ],
      "metadata": {
        "id": "iG9M5Gyshfc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "class SimpleTokenizerV2:\n",
        "    def __init__(self, vocab):\n",
        "        self.str_to_int = vocab\n",
        "        self.int_to_str = {i:t for t,i in vocab.items()}\n",
        "\n",
        "\n",
        "    def encode(self,text):\n",
        "        preprocessed = re.split(r'([,.;:?!\"()\\]|--|\\s)', text)\n",
        "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
        "        processed = [\n",
        "            item if item in self.str_to_int\n",
        "            else \"<|unk|>\" for item in preprocessed\n",
        "        ]\n",
        "        ids = [self.str_to_int[s] for s in preprocessed]\n",
        "        return ids\n",
        "\n",
        "    def decoder(self,ids):\n",
        "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
        "        text = re.sub(r'\\s+([,.?!\"()\\']+)',r'\\1',text)\n",
        "        return text"
      ],
      "metadata": {
        "id": "4PODwSU4iL9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Byte pair encoding\n"
      ],
      "metadata": {
        "id": "TXvPAW81gXAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken"
      ],
      "metadata": {
        "id": "DMT3T3wfhNR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "id": "lZ4OzeVrjqz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Hey, this is dkfjs;irfpiodskf\""
      ],
      "metadata": {
        "id": "hBH0Npl1jx4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ids = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})"
      ],
      "metadata": {
        "id": "ssIZNyhcj4Ih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "string = tokenizer.decode(ids)"
      ],
      "metadata": {
        "id": "iXmQCuhAkJSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "string\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "kHxUHP1_kMqW",
        "outputId": "10516b57-b532-4fa0-ca85-a50857073404"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hey, this is dkfjs;irfpiodskf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "as-U4GaqiKed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### input target pairs\n"
      ],
      "metadata": {
        "id": "ZDB50y8DWSEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/the-verdict.txt', 'r', encoding='utf-8') as f:\n",
        "    raw_text = f.read()"
      ],
      "metadata": {
        "id": "NQcaJAwEWVTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(raw_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apoRrzivWnuZ",
        "outputId": "68869436-ae86-44d5-da36-ef67acd547b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20479"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enc_text = tokenizer.encode(raw_text)\n",
        "enc_text[:9]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBVAhxJ0Wpd4",
        "outputId": "c9425530-a15b-4778-9b30-bc8281194e55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[40, 367, 2885, 1464, 1807, 3619, 402, 271, 10899]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enc_sample = enc_text[:50]"
      ],
      "metadata": {
        "id": "1GQlH0pjXkSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_size = 4\n",
        "\n",
        "for i in range(0, context_size+1):\n",
        "    context = enc_sample[:i]\n",
        "    desired = enc_sample[i]\n",
        "\n",
        "    # print(context, '-->', desired)\n",
        "    # print(tokenizer.decode(context), '-->', tokenizer.decode([desired]))\n",
        "    print(context)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDzVWR2mXmvm",
        "outputId": "73ee7295-24a7-496a-ca32-b7c1d999d3a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n",
            "[40]\n",
            "[40, 367]\n",
            "[40, 367, 2885]\n",
            "[40, 367, 2885, 1464]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "hQTTVQQhlzx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class GPTDatasetV1(Dataset):\n",
        "    def __init__(self,tokenizer, text, context_size, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        token_ids = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "        for i in range(0,len(text)-context_size,stride):\n",
        "            self.input_ids.append(torch.tensor(token_ids[i:i+context_size]))\n",
        "            self.target_ids.append(torch.tensor(token_ids[i+1 : i+1+context_size]))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.input_ids[index], self.target_ids[index]\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wKpZz1gag2fN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloader_v1(text, context_size=256, stride=128, batch_size=4, shuffle=True, drop_last=True, num_workers=0):\n",
        "\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "    #create dataset\n",
        "    dataset = GPTDatasetV1(tokenizer, text, context_size, stride)\n",
        "\n",
        "    #create dataloader\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        drop_last=drop_last,\n",
        "        num_workers=num_workers\n",
        "    )\n",
        "\n",
        "    return dataloader"
      ],
      "metadata": {
        "id": "YuyzmlzXl1pY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_data_loader = create_dataloader_v1(raw_text, 4, 1, 1)"
      ],
      "metadata": {
        "id": "ZPPjnLxKnAt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "abc = iter(my_data_loader)"
      ],
      "metadata": {
        "id": "MwqoQgjjoiHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(next(abc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbITq_DjovhU",
        "outputId": "c894ce26-4674-4874-e3ad-745755dfcc50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([], size=(1, 0)), tensor([], size=(1, 0))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "second_batch = next(abc)\n",
        "print(second_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLats1cRozj6",
        "outputId": "4ed8815b-6bf7-46cf-eb8b-7b1407c41bde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[ 5574,  1660,    12, 49903]]), tensor([[ 1660,    12, 49903,   438]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### token embeddings example\n"
      ],
      "metadata": {
        "id": "N-Dy_B68RojC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### token embeddings example"
      ],
      "metadata": {
        "id": "aIY2ROFZWqc2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the token embedding vector has size of vocab size(no. of tokens) X output dimention"
      ],
      "metadata": {
        "id": "3O0ot3CDWvKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_length = 5\n",
        "features = 3\n",
        "\n",
        "import torch\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "embedding_layer = torch.nn.Embedding(token_length, features)"
      ],
      "metadata": {
        "id": "98UaXCysY1pg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer.weight # this is random at first"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qytSc2l5ZJZ3",
        "outputId": "36551b56-7fd5-4446-98ea-4ffa5bc544e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.1115,  0.1204, -0.3696],\n",
              "        [-0.2404, -1.1969,  0.2093],\n",
              "        [-0.9724, -0.7550,  0.3239],\n",
              "        [-0.1085,  0.2103, -0.3908],\n",
              "        [ 0.2350,  0.6653,  0.3528]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# it is lookup operation."
      ],
      "metadata": {
        "id": "yfNXnGCIZOiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eJYlDzhEaAeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Positional Embedding\n"
      ],
      "metadata": {
        "id": "LdfNnCAMaW9z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 50257\n",
        "output_dim = 256\n",
        "\n",
        "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
      ],
      "metadata": {
        "id": "mQSpKHU3abBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 4\n",
        "dataloader = create_dataloader_v1(raw_text, max_len, max_len, 8)\n",
        "data_iter = iter(dataloader)\n",
        "input, target = next(data_iter)"
      ],
      "metadata": {
        "id": "4u6Au-a43V0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_embeddings = token_embedding_layer(input)\n"
      ],
      "metadata": {
        "id": "mfd-YAVN4DSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_len = max_len\n",
        "pos_embedding_layer = torch.nn.Embedding(context_len, output_dim)"
      ],
      "metadata": {
        "id": "HI-iFU4k4mkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_embeddings = pos_embedding_layer(torch.arange(max_len))"
      ],
      "metadata": {
        "id": "T4nKjmu840ev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_embeddings = pos_embeddings + token_embeddings"
      ],
      "metadata": {
        "id": "lJ__WXop4_Ci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EAOVvzlj5DN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Self Attention Mechanism"
      ],
      "metadata": {
        "id": "djtmIy5DkyEZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we have token embedding scores.\n",
        "# we first initialize 0 attention scores for each token.\n",
        "# take token_embedding score for query\n",
        "# do dot product of that query with each token embedding -> attention score\n"
      ],
      "metadata": {
        "id": "jQE4xSvHk3_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "ZiFgtanJjmMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# token_embedding scores\n",
        "inputs = torch.tensor([\n",
        "   [0.43, 0.15, 0.89], # Your     (x^1)\n",
        "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
        "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
        "   [0.22, 0.58, 0.33], # with     (x^4)\n",
        "   [0.77, 0.25, 0.10], # one      (x^5)\n",
        "   [0.05, 0.80, 0.55] # step     (x^6)\n",
        "])"
      ],
      "metadata": {
        "id": "WK-b6Djiju1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = inputs[1] # our query\n",
        "attn_scores = torch.empty(inputs.shape[0]) # our attn_score\n",
        "print(attn_scores)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4vG3sVGj3RP",
        "outputId": "439abbe4-d4e0-494e-91a8-2b15cc3b8dbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-9.0889e+15,  7.0368e+28,  2.8183e+20,  5.4058e-14,  9.8612e+18,\n",
            "         2.9264e+29])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i,vector in enumerate(inputs):\n",
        "    # print(i,'---',vector)\n",
        "    attn_scores[i] = torch.dot(vector, query)\n"
      ],
      "metadata": {
        "id": "CEFPZJGfkk4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(attn_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xS6jdqTdlFPK",
        "outputId": "b5c317cb-67d5-4bfe-b80a-2942a28f3736"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now we normalize it. with softmax\n",
        "norm_attn_scores = torch.softmax(attn_scores, dim=0)"
      ],
      "metadata": {
        "id": "6ViRybknvAZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.sum(norm_attn_scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5v0AHvrvXhn",
        "outputId": "2619958e-eb57-4e4b-836b-62c9e6bd7a26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_vector_x2 = torch.zeros(query.shape)\n",
        "context_vector_x2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6CCYK5DwKgx",
        "outputId": "31bbe138-35d1-450b-ab6e-4ccf1a5f1aab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to get embedding vector here for x2\n",
        "# multiply each attn_score with corresponding token_embedding vector we got and sum them\n",
        "\n",
        "for i, token_embedding_vector in enumerate(inputs):\n",
        "    context_vector_x2 += norm_attn_scores[i] * token_embedding_vector\n"
      ],
      "metadata": {
        "id": "t--pNhljvaDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_vector_x2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZITXvXExfDv",
        "outputId": "57c9fe5c-66e0-4190-e43f-a4bb4a339d61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4419, 0.6515, 0.5683])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now, we will do this for each token with respect to each token.\n",
        "# find each attention_weight for each different token, taking it as a query.\n",
        "# this can be done as input.input transpose"
      ],
      "metadata": {
        "id": "Vd2Hm_GMxhGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores = inputs @ inputs.T"
      ],
      "metadata": {
        "id": "vFhdiHg02R5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(attn_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnH6LMKU2WG2",
        "outputId": "5465db20-88b1-426d-bd21-5f03774615d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
            "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
            "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
            "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
            "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
            "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_weights = torch.softmax(attn_scores, dim=-1)"
      ],
      "metadata": {
        "id": "v8phteCa2X-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_context_vecs = attn_weights @ inputs"
      ],
      "metadata": {
        "id": "01z0INqK3uaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_context_vecs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoLow8GO3wqi",
        "outputId": "55fd008b-9c63-4fca-80c8-9907574d276d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4421, 0.5931, 0.5790],\n",
              "        [0.4419, 0.6515, 0.5683],\n",
              "        [0.4431, 0.6496, 0.5671],\n",
              "        [0.4304, 0.6298, 0.5510],\n",
              "        [0.4671, 0.5910, 0.5266],\n",
              "        [0.4177, 0.6503, 0.5645]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Self Attention with trainable weights"
      ],
      "metadata": {
        "id": "O2su9P7WlYhb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "g0tRIACple_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.tensor(\n",
        "    [[0.43, 0.15, 0.89], # Your     (x^1)\n",
        "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
        "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
        "   [0.22, 0.58, 0.33], # with     (x^4)\n",
        "   [0.77, 0.25, 0.10], # one      (x^5)\n",
        "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
        ")"
      ],
      "metadata": {
        "id": "T7RshSu0lhSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# here, we have 3 trainable weight metrices. key, query, weight.\n",
        "# we gain them by matrix multiplication with input and their correspondig weight metrics"
      ],
      "metadata": {
        "id": "jVw4ruflllxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x2 = inputs[1] #finding context vec of x2 with respect to other vectors\n",
        "x2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1uWgK3_lzjy",
        "outputId": "5d9898e6-ba68-41af-c06a-951abf81ea6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.5500, 0.8700, 0.6600])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d_in = inputs.shape[1]\n",
        "d_out = 2"
      ],
      "metadata": {
        "id": "15LcstU_mBnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining weight for key, query, value\n",
        "torch.manual_seed(123)\n",
        "Wq = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
        "Wk = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
        "Wv = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)"
      ],
      "metadata": {
        "id": "papwJ0FjmNh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Wq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lp2bk6imfuj",
        "outputId": "d42fa866-1149-481f-f972-aa47479b0129"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[0.2961, 0.5166],\n",
            "        [0.2517, 0.6886],\n",
            "        [0.0740, 0.8665]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now, we will multiply token_embedding vector with this weights to get weight, key, query metrics"
      ],
      "metadata": {
        "id": "wI1xsoc8mn_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keys = inputs @ Wk"
      ],
      "metadata": {
        "id": "BInrg5I2n061"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keys"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEqltosioS8P",
        "outputId": "6645bccb-b3bb-4ec2-85d0-8b5498a24776"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3669, 0.7646],\n",
              "        [0.4433, 1.1419],\n",
              "        [0.4361, 1.1156],\n",
              "        [0.2408, 0.6706],\n",
              "        [0.1827, 0.3292],\n",
              "        [0.3275, 0.9642]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "values = inputs @ Wv\n",
        "queries = inputs @ Wq"
      ],
      "metadata": {
        "id": "5QHzkWG0oWoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now, to get attn_scores, we do matrix multiplication of queries and key transpose"
      ],
      "metadata": {
        "id": "zcTJEBowocX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scoress = queries @ keys.T"
      ],
      "metadata": {
        "id": "1CbnJMhZ1ql2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_k = keys.shape[-1]\n",
        "attn_weights_2 = torch.softmax(attn_scoress / d_k**0.5, dim=-1)"
      ],
      "metadata": {
        "id": "pYXaE20DfQEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_vec_2 = attn_weights_2 @ values"
      ],
      "metadata": {
        "id": "q2tLyjeefW-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SelfAttention_v1(nn.Module):\n",
        "\n",
        "    def __init__(self, d_in, d_out):\n",
        "        super().__init__()\n",
        "        self.W_query = nn.Parameter(torch.rand(d_in, d_out))\n",
        "        self.W_key   = nn.Parameter(torch.rand(d_in, d_out))\n",
        "        self.W_value = nn.Parameter(torch.rand(d_in, d_out))\n",
        "\n",
        "    def forward(self, x):\n",
        "        keys = x @ self.W_key\n",
        "        queries = x @ self.W_query\n",
        "        values = x @ self.W_value\n",
        "\n",
        "        attn_scores = queries @ keys.T # omega\n",
        "        attn_weights = torch.softmax(\n",
        "            attn_scores / keys.shape[-1]**0.5, dim=-1\n",
        "        )\n",
        "\n",
        "        context_vec = attn_weights @ values\n",
        "        return context_vec"
      ],
      "metadata": {
        "id": "G2LXCxWyfbH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfAttention_v2(nn.Module):\n",
        "\n",
        "    def __init__(self, d_in, d_out, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        self.W_query = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key   = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = torch.nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        keys = self.W_key(x)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        attn_scores = queries @ keys.T\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "\n",
        "        context_vec = attn_weights @ values\n",
        "        return context_vec"
      ],
      "metadata": {
        "id": "bE_BBTDqfd_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Causal Attention"
      ],
      "metadata": {
        "id": "bXWV6MCZyBkL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "sa_v2 = SelfAttention_v2(d_in, d_out)"
      ],
      "metadata": {
        "id": "SjWkvEGeyEG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "queries = sa_v2.W_query(inputs)\n",
        "keys = sa_v2.W_key(inputs)\n"
      ],
      "metadata": {
        "id": "-9RwHNZ8zG7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "queries = sa_v2.W_query(inputs)\n",
        "keys = sa_v2.W_key(inputs)\n",
        "attn_scores = queries @ keys.T\n",
        "attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=1)\n",
        "print(attn_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bqytn5MczTZs",
        "outputId": "ffec5b55-4426-4d3d-a6e5-adfefda3f1bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1717, 0.1762, 0.1761, 0.1555, 0.1627, 0.1579],\n",
            "        [0.1636, 0.1749, 0.1746, 0.1612, 0.1605, 0.1652],\n",
            "        [0.1637, 0.1749, 0.1746, 0.1611, 0.1606, 0.1651],\n",
            "        [0.1636, 0.1704, 0.1702, 0.1652, 0.1632, 0.1674],\n",
            "        [0.1667, 0.1722, 0.1721, 0.1618, 0.1633, 0.1639],\n",
            "        [0.1624, 0.1709, 0.1706, 0.1654, 0.1625, 0.1682]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# causal attention hides attention weights above diagonal. and we take softmax after that.\n",
        "# but, in above, we already have influence of future tokens.\n"
      ],
      "metadata": {
        "id": "01npsvNTRSYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# so we do different way.\n",
        "# we use tril function of python torch to create mask"
      ],
      "metadata": {
        "id": "61htOjQRRl15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_length = 6"
      ],
      "metadata": {
        "id": "ufLfvZZnR0Gi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.ones(context_length, context_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDsR5p3BSAkU",
        "outputId": "011a0ce2-f8d7-4a99-9021-ce435a2f91fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask_simple = torch.tril(torch.ones(context_length, context_length))\n",
        "mask_simple"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SbWyPpPSDG7",
        "outputId": "a8a5e555-5ea9-4f3a-e144-de7da878d5a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0., 0., 0., 0.],\n",
              "        [1., 1., 0., 0., 0., 0.],\n",
              "        [1., 1., 1., 0., 0., 0.],\n",
              "        [1., 1., 1., 1., 0., 0.],\n",
              "        [1., 1., 1., 1., 1., 0.],\n",
              "        [1., 1., 1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now applying this mask to our attn_weights\n",
        "updated_attn_wts = attn_weights * mask_simple\n",
        "updated_attn_wts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQznkibMSUg7",
        "outputId": "a3e4d567-ed5a-423c-dd01-127ff73227dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1717, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1636, 0.1749, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1637, 0.1749, 0.1746, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1636, 0.1704, 0.1702, 0.1652, 0.0000, 0.0000],\n",
              "        [0.1667, 0.1722, 0.1721, 0.1618, 0.1633, 0.0000],\n",
              "        [0.1624, 0.1709, 0.1706, 0.1654, 0.1625, 0.1682]],\n",
              "       grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "row_sum = updated_attn_wts.sum(dim=1, keepdim=True)\n",
        "row_sum"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvGq6Jx1TSYe",
        "outputId": "2bcfd7f9-6209-4a5e-f556-00b0a71adbde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000],\n",
              "        [1.6667],\n",
              "        [2.2121],\n",
              "        [2.6921],\n",
              "        [3.1301],\n",
              "        [3.5382]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "updated_attn_wts = mask_simple / row_sum"
      ],
      "metadata": {
        "id": "HNcFiQY6TZLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "updated_attn_wts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEyKoTTaTkJR",
        "outputId": "f4a3a8cf-ef1e-41cc-a9d3-85f256a987ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.6000, 0.6000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.4521, 0.4521, 0.4521, 0.0000, 0.0000, 0.0000],\n",
              "        [0.3715, 0.3715, 0.3715, 0.3715, 0.0000, 0.0000],\n",
              "        [0.3195, 0.3195, 0.3195, 0.3195, 0.3195, 0.0000],\n",
              "        [0.2826, 0.2826, 0.2826, 0.2826, 0.2826, 0.2826]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this is so fucking weird, let's just do better way"
      ],
      "metadata": {
        "id": "W7SzAAaFTu5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# what we do is, we create mask with '1' value in upper tringular, replace it with -inf value.\n",
        "# then take softmax, so it turns out to be 0."
      ],
      "metadata": {
        "id": "KqOtGU61TyYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask = torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
        "mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAxVD8w-VAa3",
        "outputId": "47141893-e8ac-4493-9266-03e348a26578"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1., 1., 1., 1., 1.],\n",
              "        [0., 0., 1., 1., 1., 1.],\n",
              "        [0., 0., 0., 1., 1., 1.],\n",
              "        [0., 0., 0., 0., 1., 1.],\n",
              "        [0., 0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores # not normalized."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2teZFGbUVWBk",
        "outputId": "ab73f00a-9860-4e69-affa-afd0d28e0a8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3111, 0.3479, 0.3471, 0.1714, 0.2350, 0.1928],\n",
              "        [0.1655, 0.2602, 0.2576, 0.1445, 0.1384, 0.1790],\n",
              "        [0.1667, 0.2602, 0.2577, 0.1443, 0.1391, 0.1784],\n",
              "        [0.0510, 0.1080, 0.1064, 0.0643, 0.0476, 0.0835],\n",
              "        [0.1415, 0.1875, 0.1863, 0.0987, 0.1121, 0.1174],\n",
              "        [0.0476, 0.1192, 0.1171, 0.0731, 0.0477, 0.0966]],\n",
              "       grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked_attn_scores = attn_scores.masked_fill(mask.bool(), float('-inf'))\n",
        "masked_attn_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJKNzR41VcWC",
        "outputId": "24867948-a402-4911-dd08-852ae2786a45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3111,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
              "        [0.1655, 0.2602,   -inf,   -inf,   -inf,   -inf],\n",
              "        [0.1667, 0.2602, 0.2577,   -inf,   -inf,   -inf],\n",
              "        [0.0510, 0.1080, 0.1064, 0.0643,   -inf,   -inf],\n",
              "        [0.1415, 0.1875, 0.1863, 0.0987, 0.1121,   -inf],\n",
              "        [0.0476, 0.1192, 0.1171, 0.0731, 0.0477, 0.0966]],\n",
              "       grad_fn=<MaskedFillBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now we do softmax\n",
        "attn_weights = torch.softmax(masked_attn_scores / keys.shape[-1]** 0.5, dim=-1)\n",
        "attn_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGxqFyl6V2pc",
        "outputId": "0510d17e-23cc-4d7c-cf5a-2272e418dfbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.4833, 0.5167, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.3190, 0.3408, 0.3402, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2445, 0.2545, 0.2542, 0.2468, 0.0000, 0.0000],\n",
              "        [0.1994, 0.2060, 0.2058, 0.1935, 0.1953, 0.0000],\n",
              "        [0.1624, 0.1709, 0.1706, 0.1654, 0.1625, 0.1682]],\n",
              "       grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Dropout example\n",
        "example = torch.ones(6,6)\n",
        "# example\n",
        "dropout = torch.nn.Dropout(0.2)\n",
        "print(dropout(example))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFtrB5V3WFwm",
        "outputId": "fa45ebde-9df3-496b-8a65-fe245a2f4785"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2., 0., 2., 2., 2., 2.],\n",
            "        [2., 0., 2., 0., 2., 2.],\n",
            "        [0., 0., 2., 0., 2., 0.],\n",
            "        [2., 0., 2., 0., 2., 2.],\n",
            "        [2., 2., 0., 2., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 2.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dropout(attn_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qu6woV7Yt5S",
        "outputId": "8cd3ce97-6169-405e-92e5-158cce8b480e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.9665, 1.0335, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.6380, 0.0000, 0.6804, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.5090, 0.5085, 0.4936, 0.0000, 0.0000],\n",
              "        [0.3988, 0.4120, 0.4116, 0.0000, 0.0000, 0.0000],\n",
              "        [0.3249, 0.3418, 0.0000, 0.3308, 0.3249, 0.0000]],\n",
              "       grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# implementing class for this.\n",
        "batch = torch.stack((inputs, inputs), dim=0)\n",
        "batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYiV265Yb4Cm",
        "outputId": "21676d41-5784-41aa-f408-310cbb1d1ff6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.4300, 0.1500, 0.8900],\n",
              "         [0.5500, 0.8700, 0.6600],\n",
              "         [0.5700, 0.8500, 0.6400],\n",
              "         [0.2200, 0.5800, 0.3300],\n",
              "         [0.7700, 0.2500, 0.1000],\n",
              "         [0.0500, 0.8000, 0.5500]],\n",
              "\n",
              "        [[0.4300, 0.1500, 0.8900],\n",
              "         [0.5500, 0.8700, 0.6600],\n",
              "         [0.5700, 0.8500, 0.6400],\n",
              "         [0.2200, 0.5800, 0.3300],\n",
              "         [0.7700, 0.2500, 0.1000],\n",
              "         [0.0500, 0.8000, 0.5500]]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) initializing query, key, value\n",
        "# 2) find attention score\n",
        "# 3) masking them\n",
        "# 4) find weights\n",
        "# 5) find context vector"
      ],
      "metadata": {
        "id": "vCdVM-78cWS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "MscFWFvDrTFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Causal_attention(nn.Module):\n",
        "\n",
        "    def __init__(self, d_in, d_out, context_length, qkv_bias=False, dropout=0.2):\n",
        "        super().__init__()\n",
        "\n",
        "        self.W_queries = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_keys = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_values = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        no_of_batches, token_nos, d_in = x.shape\n",
        "        keys = self.W_keys(x)\n",
        "        queries = self.W_queries(x)\n",
        "        values = self.W_values(x)\n",
        "        attn_scores = queries @ keys.transpose(1, 2)\n",
        "        attn_scores.masked_fill_(  # New, _ ops are in-place\n",
        "            self.mask.bool()[:token_nos, :token_nos], -torch.inf)  # Changed num_tokens to token_nos\n",
        "        attn_weights = torch.softmax(\n",
        "            attn_scores / keys.shape[-1]**0.5, dim=-1\n",
        "        )\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        context_vec = attn_weights @ values\n",
        "        return context_vec"
      ],
      "metadata": {
        "id": "sMUv8hzncDVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing Multi head attention"
      ],
      "metadata": {
        "id": "hgRvDCLgqnyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiheadAttentionWrapper(nn.Module):\n",
        "    def __init__(self, d_in, d_out, num_heads, context_length, qkv_bias=False, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList(\n",
        "            [ Causal_attention(d_in, d_out, context_length, qkv_bias, dropout)\n",
        "            for _ in range(num_heads)]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "         return torch.cat([head(x) for head in self.heads], dim=-1)"
      ],
      "metadata": {
        "id": "PTpV5gJbqst7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "inputs = torch.tensor(\n",
        "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
        "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
        "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
        "   [0.22, 0.58, 0.33], # with     (x^4)\n",
        "   [0.77, 0.25, 0.10], # one      (x^5)\n",
        "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
        ")\n",
        "batch = torch.stack((inputs, inputs), dim=0)\n",
        "print(batch.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzoaYHf0r48k",
        "outputId": "af608445-504f-4209-857e-d82473b8b8b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 6, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "context_length = batch.shape[1] # This is the number of tokens = 6\n",
        "d_in, d_out = 3, 2\n",
        "mha = MultiheadAttentionWrapper(d_in, d_out, context_length, 0.0, num_heads=2)\n",
        "context_vecs = mha(batch)\n",
        "print(context_vecs)\n",
        "print(\"context_vecs.shape:\", context_vecs.shape)"
      ],
      "metadata": {
        "id": "ZFdWmhCbr_vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mha1 = MultiheadAttentionWrapper(d_in=inputs.shape[-1], d_out=2, num_heads=2, context_length=inputs.shape[0])\n",
        "mha1(batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rh6DZD0SsQ4i",
        "outputId": "badd1dd6-0796-4fcb-cc7b-a9cab5450ae9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.5939, -0.0048, -0.1175,  0.0239],\n",
              "         [-0.6131, -0.1510, -0.2051,  0.2834],\n",
              "         [-0.4096, -0.0972, -0.1347,  0.1799],\n",
              "         [-0.2493, -0.0624, -0.2145,  0.3590],\n",
              "         [-0.3737, -0.1078, -0.1126,  0.1841],\n",
              "         [-0.4237, -0.1626, -0.1360,  0.2489]],\n",
              "\n",
              "        [[ 0.0000,  0.0000, -0.1175,  0.0239],\n",
              "         [ 0.0000,  0.0000, -0.0561,  0.0114],\n",
              "         [-0.6125, -0.1987, -0.2326,  0.3586],\n",
              "         [-0.5532, -0.2132, -0.2145,  0.3590],\n",
              "         [-0.3737, -0.1078, -0.2130,  0.2978],\n",
              "         [-0.3865, -0.1549, -0.1497,  0.2781]]], grad_fn=<CatBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multihead with weight split"
      ],
      "metadata": {
        "id": "aIjhVJrQuxRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# why we need this? because when we try to implement multihead attention with bunch of causal attn, we do matrix multiplication\n",
        "# which is compulationally heavy. so we split the weights for key, query and value wt matrix.\n"
      ],
      "metadata": {
        "id": "b1nM3PSCu_mZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# other thing to note is, no. of feature(col dim of token embedding / head_dim) * no. of heads = d_out (in our wt matrix i.e d_in x d_out)\n",
        "import torch\n",
        "inputs = torch.tensor(\n",
        "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
        "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
        "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
        "   [0.22, 0.58, 0.33], # with     (x^4)\n",
        "   [0.77, 0.25, 0.10], # one      (x^5)\n",
        "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
        ")\n",
        "batch = torch.stack((inputs, inputs), dim=0)\n",
        "print(batch.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBnzviCQcjp_",
        "outputId": "5cf77ceb-f97e-406f-b20d-eabb5a3f1c9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 6, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "5fs4gfVv59qz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, d_in, d_out, context_length, no_heads, qkv_bias=False, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.d_in = d_in\n",
        "        self.d_out = d_out\n",
        "        self.context_length = context_length\n",
        "        self.no_heads = no_heads\n",
        "        # we will also need head_dim\n",
        "        self.head_dim = d_out// no_heads\n",
        "\n",
        "        # then we initialise weights\n",
        "        self.W_queries = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_keys = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_values = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "\n",
        "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer(\n",
        "            \"mask\",\n",
        "            torch.triu(torch.ones(context_length, context_length),\n",
        "                       diagonal=1)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        no_of_batches, token_nos, d_in = x.shape\n",
        "\n",
        "        # initialising key, queries and values\n",
        "        queries = self.W_queries(x)\n",
        "        keys = self.W_keys(x)\n",
        "        values = self.W_values(x)\n",
        "\n",
        "        # we will view this/split this other way\n",
        "        queries = queries.view(no_of_batches, token_nos, self.no_heads, self.head_dim)\n",
        "        keys = keys.view(no_of_batches, token_nos, self.no_heads, self.head_dim)\n",
        "        values = values.view(no_of_batches, token_nos, self.no_heads, self.head_dim)\n",
        "\n",
        "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
        "        queries = queries.transpose(1,2)\n",
        "        values = values.transpose(1,2)\n",
        "        keys = keys.transpose(1,2)\n",
        "\n",
        "        attn_score = queries @ keys.transpose(2,3) # here keys dim could be [1,3,2,3] --> so transpose will be for dim 1,2 --. [1,2,3,3]\n",
        "\n",
        "        # Original mask truncated to the number of tokens and converted to boolean\n",
        "        mask_bool = self.mask.bool()[:token_nos, :token_nos]\n",
        "\n",
        "        attn_score.masked_fill(mask_bool, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_score / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights= self.dropout(attn_weights)\n",
        "\n",
        "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
        "        context_vec = context_vec.contiguous().view(no_of_batches, token_nos, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec) # optional projection\n",
        "\n",
        "        return context_vec"
      ],
      "metadata": {
        "id": "bQHp4lWvdI7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dummy GPT Architecture"
      ],
      "metadata": {
        "id": "ViGv7fLpYH2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# text -> tokens -> token_ids -> token_embeddings + position_embeddings -> input_embeddings\n",
        "# this goes into transformer block."
      ],
      "metadata": {
        "id": "u3rGIztOYKhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GPT_CONFIGURATION_PARAMS = {\n",
        "    \"vocab_size\": 50257,\n",
        "    \"n_heads\": 12,\n",
        "    \"context_length\": 1024,\n",
        "    \"emb_dim\": 768,\n",
        "    \"n_layers\": 12,\n",
        "    \"dropout\": 0.1,\n",
        "    \"qkv_bias\": False\n",
        "}"
      ],
      "metadata": {
        "id": "MlplrvNZZNKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "XRekgyvNhGOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DummyGPTarchitecture(nn.Module):\n",
        "\n",
        "    def __init__(self, cfg): #cfg - configuration block\n",
        "        super().__init__()\n",
        "        self.token_emb = nn.Embedding(cfg['vocab_size'], cfg['emb_dim'])\n",
        "        self.position_emb = nn.Embedding(cfg['vocab_size'], cfg['emb_dim'])\n",
        "        self.drop_rate = nn.Dropout(cfg['dropout'])\n",
        "\n",
        "        # initialising transformerb lock\n",
        "        self.transformer_blocks = nn.Sequential(\n",
        "        *[DummyTransformerBlock(cfg) for _ in range(cfg['n_layers'])])\n",
        "\n",
        "        # and then, there was a normalisation layer\n",
        "        self.final_norm = DummyNormLayer(cfg['emb_dim'])\n",
        "\n",
        "        #and final output\n",
        "        self.out_head=nn.Linear(\n",
        "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, id_idx):\n",
        "        batch_size, sequence_len = id_idx.shape\n",
        "        tok_embs = self.token_emb(id_idx)\n",
        "        pos_embs = self.position_emb(torch.arange(sequence_len, device=id_idx.device))\n",
        "        input_embs = tok_embs + pos_embs\n",
        "        input_embs = self.drop_rate(input_embs)\n",
        "        input_embs = self.transformer_blocks(input_embs)\n",
        "        input_embs = self.final_norm(input_embs)\n",
        "        logits = self.out_head(input_embs)\n",
        "\n",
        "        return logits\n",
        "\n",
        "\n",
        "class DummyTransformerBlock(nn.Module):\n",
        "      def __init__(self,cfg):\n",
        "          super().__init__()\n",
        "\n",
        "      def forward(self, x):\n",
        "          return x\n",
        "\n",
        "class DummyNormLayer(nn.Module):\n",
        "      def __init__(self, norm_shape, eps = 1e-5):\n",
        "          super().__init__()\n",
        "\n",
        "      def forward(self,x):\n",
        "          return x\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "E7JyiEOiYoHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ILyB-fwZhJGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## step 1: Tokenization"
      ],
      "metadata": {
        "id": "65lExBLzhKtZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken"
      ],
      "metadata": {
        "id": "crW2xOY8hNIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "batch=[]\n",
        "txt1 = \"I am learning LLM\"\n",
        "txt2 = \"IT is intersting\"\n",
        "batch.append(torch.tensor(tokenizer.encode(txt1)))"
      ],
      "metadata": {
        "id": "hNTJE67_hXUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch.append(torch.tensor(tokenizer.encode(txt2)))"
      ],
      "metadata": {
        "id": "zU6OoGe2huaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ll2aLF1UhxRG",
        "outputId": "a1737a63-a7ff-4cb6-9f22-cd168c9bd495"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([   40,   716,  4673, 27140,    44]), tensor([2043,  318,  987,  301,  278])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch = torch.stack(batch, dim=0)\n",
        "batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYWMU5Dkh1FV",
        "outputId": "785d6051-699b-4698-bb42-67064f3c3708"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   40,   716,  4673, 27140,    44],\n",
              "        [ 2043,   318,   987,   301,   278]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gN8i_o_8i6Ag",
        "outputId": "e484f3eb-d26c-4616-d333-fb633833ca11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   40,   716,  4673, 27140,    44],\n",
              "        [ 2043,   318,   987,   301,   278]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating instance of dummy gpt"
      ],
      "metadata": {
        "id": "0v2ExYboi8GA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "gpt = DummyGPTarchitecture(GPT_CONFIGURATION_PARAMS)\n",
        "logits = gpt(batch)"
      ],
      "metadata": {
        "id": "POAC8ZXajArR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(logits)"
      ],
      "metadata": {
        "id": "g9xgKQAZjhm0",
        "outputId": "41c1736f-3837-4c6f-8b48-337b9e78cd2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.7108,  0.5645, -0.5606,  ...,  1.3645, -0.3677,  0.9244],\n",
            "         [ 0.8104, -1.1496, -1.6109,  ...,  0.5917, -0.5173,  2.0143],\n",
            "         [ 0.7115, -0.7746, -0.4637,  ..., -0.3947,  0.7802, -0.8231],\n",
            "         [ 0.6124,  0.2343, -0.5435,  ..., -0.4446, -1.6082, -0.1409],\n",
            "         [-1.2540,  0.4096,  0.4182,  ..., -1.7074,  0.2678, -0.8032]],\n",
            "\n",
            "        [[-0.1162,  0.0534,  0.9246,  ...,  0.8270,  0.3381, -0.3394],\n",
            "         [-0.4163, -0.9663, -2.6294,  ...,  2.2240, -1.1728,  1.7489],\n",
            "         [ 1.7931, -0.7639,  0.2189,  ...,  0.1075,  1.7238,  0.6194],\n",
            "         [ 0.0846, -0.0361, -0.3526,  ..., -0.8309, -0.3208,  2.0221],\n",
            "         [-0.9283,  0.1035,  0.7228,  ..., -0.8316,  0.8789, -2.0160]]],\n",
            "       grad_fn=<UnsafeViewBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# even thought this is random, it worked, so i am happy!"
      ],
      "metadata": {
        "id": "vDTYJddhjj72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Layer Normalization"
      ],
      "metadata": {
        "id": "QNAH0FwvaSMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# below is example for this"
      ],
      "metadata": {
        "id": "pS1EJihhb8SV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "Z2yqupHpac1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "random_sample=torch.randn(3,5)"
      ],
      "metadata": {
        "id": "YOdebn8bbm_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "iY6ux5OWb0CK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer = nn.Sequential(nn.Linear(5,6), nn.ReLU())\n",
        "output = layer(random_sample)"
      ],
      "metadata": {
        "id": "mqnhW8kJb6LR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJ3xzxeWcKSE",
        "outputId": "36e87012-cd92-4836-85db-4acf4f3b2391"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.3571, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2610],\n",
              "        [0.0000, 0.0000, 0.0000, 0.0811, 0.0000, 0.1129]],\n",
              "       grad_fn=<ReluBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean = output.mean(dim=-1, keepdim=True)\n",
        "print(mean)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLfhYBAHcQLf",
        "outputId": "99f9be9d-87a2-4d17-8525-b95c7b8c18ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0595],\n",
            "        [0.0435],\n",
            "        [0.0323]], grad_fn=<MeanBackward1>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "var = output.var(dim=-1, keepdim=True)\n",
        "print(var)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVpWg7eFcpnP",
        "outputId": "d1b2bc79-405b-497e-f1c6-feccf7758442"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0212],\n",
            "        [0.0114],\n",
            "        [0.0026]], grad_fn=<VarBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "norm_out =( output - mean)/ torch.sqrt(var)"
      ],
      "metadata": {
        "id": "2OM8zD37ctuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(norm_out.mean(dim=-1,keepdim=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bm83va3xdG6i",
        "outputId": "0aa3b240-7981-4d61-85fe-d2f6918e2fd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-9.9341e-09],\n",
            "        [-9.9341e-09],\n",
            "        [-9.9341e-09]], grad_fn=<MeanBackward1>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.set_printoptions(sci_mode=False)"
      ],
      "metadata": {
        "id": "ZbyIa4nAdTZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(norm_out.mean(dim=-1,keepdim=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgbwP4RVdaKf",
        "outputId": "229dbbeb-aa6f-4a8b-b513-ea7ce8afcba5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0000],\n",
            "        [-0.0000],\n",
            "        [-0.0000]], grad_fn=<MeanBackward1>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now making a layernorm class\n",
        "class LayerNormalization(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "        norm_x = (x-mean)/torch.sqrt(var + self.eps)\n",
        "\n",
        "        return self.scale*norm_x + self.shift\n"
      ],
      "metadata": {
        "id": "zDOXLbQfde66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ln = LayerNormalization(emb_dim=5)\n",
        "out_ln = ln(random_sample)\n",
        "mean = out_ln.mean(dim=-1, keepdim=True)\n",
        "var = out_ln.var(dim=-1, unbiased=False, keepdim=True)\n",
        "print(\"Mean:\\n\", mean)\n",
        "print(\"Variance:\\n\", var)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiL9EmNJg4kp",
        "outputId": "3d89e1d8-9095-4954-fe6c-8ec52c28c7cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean:\n",
            " tensor([[-0.0000],\n",
            "        [ 0.0000],\n",
            "        [ 0.0000]], grad_fn=<MeanBackward1>)\n",
            "Variance:\n",
            " tensor([[1.0000],\n",
            "        [1.0000],\n",
            "        [0.9999]], grad_fn=<VarBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GELU Activation function and Feedforward NN"
      ],
      "metadata": {
        "id": "x4dMki3R4KgD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# used in feed forward nn, in transformer block"
      ],
      "metadata": {
        "id": "FLXHsICb4OUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch"
      ],
      "metadata": {
        "id": "uGucaV6hCz0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GELUActivation(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # we use approximation\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "            (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))"
      ],
      "metadata": {
        "id": "VOfNr2m2CTM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class feedForwardNN(nn.Module):\n",
        "    # this has linear layer, expansion, contraction\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(cfg['emb_dim'], 4*cfg['emb_dim']),\n",
        "            GELUActivation(),\n",
        "            nn.Linear(4*cfg['emb_dim'], cfg['emb_dim'])\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.layers(x)\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "w_gm8hHWCtNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ffn = feedForwardNN(GPT_CONFIGURATION_PARAMS)\n",
        "x = torch.randn(2,3,768)\n",
        "a = ffn(x)\n",
        "print(a.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVmhFFA2Dm5m",
        "outputId": "cca3cc41-7b63-4b99-fc08-3ad7a63713d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Shortcut connections"
      ],
      "metadata": {
        "id": "47T9odMGBR2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "LADLgIuKBccH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class shortcutConnections(nn.Module):\n",
        "    def __init__(self, layer_size, use_shortcut):\n",
        "        super().__init__()\n",
        "        self.use_shortcut = use_shortcut\n",
        "        self.model = nn.ModuleList([\n",
        "            nn.Sequential(nn.Linear(layer_size[0], layer_size[1], GELUActivation())),\n",
        "            nn.Sequential(nn.Linear(layer_size[1], layer_size[2], GELUActivation())),\n",
        "            nn.Sequential(nn.Linear(layer_size[2], layer_size[3], GELUActivation())),\n",
        "            # nn.Sequential(nn.Linear(layer_size[3], layer_size[4], GELUActivation()))\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x is input\n",
        "        for layer in self.model:\n",
        "            output = layer(x)\n",
        "            if self.use_shortcut and x.shape == output.shape:\n",
        "                x = output + x\n",
        "            else:\n",
        "                x = output\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "s_nShh9CBUPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer_sizes = [3,3,3,1]\n",
        "inputs = [1. , 0. , -1.]\n",
        "inputs = torch.tensor(inputs)"
      ],
      "metadata": {
        "id": "4G2uspPzDLeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "model_without_shortcut = shortcutConnections(layer_sizes, False)"
      ],
      "metadata": {
        "id": "DSdF_UhXDdnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "abc = iter(model_without_shortcut.named_parameters())\n",
        "next(abc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "8-Pldak4FlsJ",
        "outputId": "fcb2ef7e-f5c8-42ec-b9b6-e9ab20c40526"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model_without_shortcut' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1620511541.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mabc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_without_shortcut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model_without_shortcut' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Caso5OjkH1Uc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_gradients(model, x):\n",
        "    # Forward pass\n",
        "    output = model(x)\n",
        "    target = torch.tensor([[0.]])\n",
        "\n",
        "    # Calculate loss based on how close the target\n",
        "    # and output are\n",
        "    loss = nn.MSELoss()\n",
        "    loss = loss(output, target)\n",
        "\n",
        "    # Backward pass to calculate the gradients\n",
        "    loss.backward()\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            # Print the mean absolute gradient of the weights\n",
        "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")"
      ],
      "metadata": {
        "id": "gjIdLSpHEK9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(print_gradients(model_without_shortcut, inputs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2645YwccER6b",
        "outputId": "be3ec751-4521-47d6-e11c-fc39d149b1b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model.0.0.weight has gradient mean of 0.05872293934226036\n",
            "model.1.0.weight has gradient mean of 0.09259593486785889\n",
            "model.2.0.weight has gradient mean of 0.4166198968887329\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/loss.py:634: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_with_shortcut = shortcutConnections(layer_sizes, True)\n",
        "print(print_gradients(model_with_shortcut, inputs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7sLsPKbDnvX",
        "outputId": "3133f1a9-7f01-4510-e80c-e9be72557b6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model.0.0.weight has gradient mean of 0.07365316152572632\n",
            "model.1.0.weight has gradient mean of 0.035481046885252\n",
            "model.2.0.weight has gradient mean of 0.31351932883262634\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/loss.py:634: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer Architecture"
      ],
      "metadata": {
        "id": "XB5u84RT5GGf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerArchitect(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(cfg[\"emb_dim\"], cfg[\"emb_dim\"], cfg[\"context_length\"], cfg[\"n_heads\"], cfg[\"qkv_bias\"], cfg[\"dropout\"])\n",
        "        self.dropout_layer = nn.Dropout(cfg[\"dropout\"])\n",
        "        self.norm1 = LayerNormalization(cfg[\"emb_dim\"])\n",
        "        self.norm2 = LayerNormalization(cfg[\"emb_dim\"])\n",
        "        self.feed_forward = feedForwardNN(cfg)\n",
        "\n",
        "    def forward(self, x):\n",
        "        og_input = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x)\n",
        "        x = self.dropout_layer(x)\n",
        "\n",
        "        x = x + og_input\n",
        "\n",
        "        og_input = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.feed_forward(x)\n",
        "        x = self.dropout_layer(x)\n",
        "        x = x + og_input\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "XOZPEyol5Msd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9UNez60i_Ava"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GPT_CONFIGURATION_PARAMS = {\n",
        "    \"vocab_size\": 50257,\n",
        "    \"n_heads\": 12,\n",
        "    \"context_length\": 1024,\n",
        "    \"emb_dim\": 768,\n",
        "    \"n_layers\": 12,\n",
        "    \"dropout\": 0.1,\n",
        "    \"qkv_bias\": False\n",
        "}"
      ],
      "metadata": {
        "id": "_wU-NIgdH26a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "x = torch.rand(2,4,768)\n",
        "transformer = TransformerArchitect(GPT_CONFIGURATION_PARAMS)\n",
        "y = transformer(x)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25CGlYu-_CKM",
        "outputId": "db5e1ed4-3b1c-4ebc-fae8-8c8490ab3a2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 4, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPT Architecture from scratch (124M Parameters)"
      ],
      "metadata": {
        "id": "R9W60MS1HWHY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "kprE17GgHbGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTArchitecture(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.embedding_layer = nn.Embedding(cfg['vocab_size'], cfg['emb_dim'])\n",
        "        self.pos_emb_layer = nn.Embedding(cfg['context_length'], cfg['emb_dim'])\n",
        "        self.drop_emb = nn.Dropout(cfg['dropout'])\n",
        "\n",
        "        self.transformer_blocks = nn.Sequential( *[TransformerArchitect(cfg) for _ in range(cfg['n_layers'])])\n",
        "        self.final_norm = LayerNormalization(cfg['emb_dim'])\n",
        "        self.output_head = nn.Linear(\n",
        "            cfg['emb_dim'], cfg['vocab_size'], bias=False\n",
        "        )\n",
        "\n",
        "    def forward(self, id_idx):\n",
        "        batch_size, seq_len = id_idx.shape\n",
        "        token_emb = self.embedding_layer(id_idx)\n",
        "        pos_emb = self.pos_emb_layer(torch.arange(seq_len, device=id_idx.device))\n",
        "        x = token_emb + pos_emb\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.transformer_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.output_head(x)\n",
        "        return logits\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ITjPBb-1HdGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "model = GPTArchitecture(GPT_CONFIGURATION_PARAMS)\n",
        "# Corrected: Generate integer tensor for token IDs\n",
        "batch = torch.randint(0, GPT_CONFIGURATION_PARAMS['vocab_size'], (2, 4), dtype=torch.long)\n",
        "out = model(batch)\n",
        "print(\"Input batch:\\n\", batch)\n",
        "print(\"\\nOutput shape:\", out.shape)\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nRl-s2PLlOd",
        "outputId": "e1af7f34-ad3f-43d4-ab74-b2d79469e45c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input batch:\n",
            " tensor([[25371, 42188, 47556,  8856],\n",
            "        [13224, 29264, 30628,  7204]])\n",
            "\n",
            "Output shape: torch.Size([2, 4, 50257])\n",
            "tensor([[[-0.4839, -1.2559, -0.3680,  ...,  0.3904,  0.1283, -0.3099],\n",
            "         [ 0.2628, -0.5918,  0.4738,  ..., -0.8778,  0.2563, -0.2689],\n",
            "         [ 1.9126, -0.8372, -0.5461,  ...,  0.4070, -0.3218, -0.9181],\n",
            "         [-0.2324, -0.2113,  0.4055,  ...,  0.4150,  0.2015, -0.5003]],\n",
            "\n",
            "        [[-0.2270,  0.6004,  0.4399,  ...,  0.2319, -0.0710, -1.0960],\n",
            "         [ 0.1872, -0.1137,  0.2155,  ...,  0.1230,  0.0596,  0.7125],\n",
            "         [ 0.7089,  0.0151,  0.3350,  ...,  0.4523, -0.4390,  1.1430],\n",
            "         [-0.7643, -0.1387,  0.9632,  ...,  0.2284, -0.4543,  0.1508]]],\n",
            "       grad_fn=<UnsafeViewBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Total number of parameters: {total_params:,}\")"
      ],
      "metadata": {
        "id": "7_3TFueoA7X-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b354f954-a437-4f6c-f3db-32044097da7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters: 163,009,536\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cScomTjsNu12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predicting the next word"
      ],
      "metadata": {
        "id": "XBuzTkTTbuAj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_token(model, idx, max_new_tokens, context_size):\n",
        "    # if size is < context_size then we drop it\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "\n",
        "        with torch.no_grad():\n",
        "          logits = model(idx_cond)\n",
        "\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        probs = torch.softmax(logits, dim=-1)\n",
        "        idx_next = torch.argmax(probs, dim=-1, keepdim=True)  # (batch, 1)\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
        "\n",
        "    return idx\n"
      ],
      "metadata": {
        "id": "oqBOCMERbwJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_context = \"Hey there\"\n"
      ],
      "metadata": {
        "id": "RQmoVpMZqjRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "id": "bFYrCag7r9kI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encode = tokenizer.encode(start_context)\n",
        "encoded_tensor = torch.tensor(encode).unsqueeze(0)"
      ],
      "metadata": {
        "id": "w1PngaM2sBON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(encoded_tensor)"
      ],
      "metadata": {
        "id": "26cb1uC7sPgO",
        "outputId": "6c495034-3abc-46ca-a4f6-b99917c29219",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[10814,   612]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "id": "oNqA-K-7sXOt",
        "outputId": "eb2eee04-d4ce-41f7-83f9-4d9bc6d3154b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTArchitecture(\n",
              "  (embedding_layer): Embedding(50257, 768)\n",
              "  (pos_emb_layer): Embedding(1024, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (transformer_blocks): Sequential(\n",
              "    (0): TransformerArchitect(\n",
              "      (multihead_attention): MultiHeadAttention(\n",
              "        (W_queries): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_keys): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_values): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
              "      (norm1): LayerNormalization()\n",
              "      (norm2): LayerNormalization()\n",
              "      (feed_forward): feedForwardNN(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELUActivation()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (1): TransformerArchitect(\n",
              "      (multihead_attention): MultiHeadAttention(\n",
              "        (W_queries): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_keys): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_values): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
              "      (norm1): LayerNormalization()\n",
              "      (norm2): LayerNormalization()\n",
              "      (feed_forward): feedForwardNN(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELUActivation()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (2): TransformerArchitect(\n",
              "      (multihead_attention): MultiHeadAttention(\n",
              "        (W_queries): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_keys): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_values): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
              "      (norm1): LayerNormalization()\n",
              "      (norm2): LayerNormalization()\n",
              "      (feed_forward): feedForwardNN(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELUActivation()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (3): TransformerArchitect(\n",
              "      (multihead_attention): MultiHeadAttention(\n",
              "        (W_queries): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_keys): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_values): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
              "      (norm1): LayerNormalization()\n",
              "      (norm2): LayerNormalization()\n",
              "      (feed_forward): feedForwardNN(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELUActivation()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (4): TransformerArchitect(\n",
              "      (multihead_attention): MultiHeadAttention(\n",
              "        (W_queries): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_keys): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_values): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
              "      (norm1): LayerNormalization()\n",
              "      (norm2): LayerNormalization()\n",
              "      (feed_forward): feedForwardNN(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELUActivation()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (5): TransformerArchitect(\n",
              "      (multihead_attention): MultiHeadAttention(\n",
              "        (W_queries): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_keys): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_values): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
              "      (norm1): LayerNormalization()\n",
              "      (norm2): LayerNormalization()\n",
              "      (feed_forward): feedForwardNN(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELUActivation()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (6): TransformerArchitect(\n",
              "      (multihead_attention): MultiHeadAttention(\n",
              "        (W_queries): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_keys): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_values): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
              "      (norm1): LayerNormalization()\n",
              "      (norm2): LayerNormalization()\n",
              "      (feed_forward): feedForwardNN(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELUActivation()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (7): TransformerArchitect(\n",
              "      (multihead_attention): MultiHeadAttention(\n",
              "        (W_queries): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_keys): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_values): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
              "      (norm1): LayerNormalization()\n",
              "      (norm2): LayerNormalization()\n",
              "      (feed_forward): feedForwardNN(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELUActivation()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (8): TransformerArchitect(\n",
              "      (multihead_attention): MultiHeadAttention(\n",
              "        (W_queries): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_keys): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_values): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
              "      (norm1): LayerNormalization()\n",
              "      (norm2): LayerNormalization()\n",
              "      (feed_forward): feedForwardNN(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELUActivation()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (9): TransformerArchitect(\n",
              "      (multihead_attention): MultiHeadAttention(\n",
              "        (W_queries): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_keys): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_values): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
              "      (norm1): LayerNormalization()\n",
              "      (norm2): LayerNormalization()\n",
              "      (feed_forward): feedForwardNN(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELUActivation()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (10): TransformerArchitect(\n",
              "      (multihead_attention): MultiHeadAttention(\n",
              "        (W_queries): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_keys): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_values): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
              "      (norm1): LayerNormalization()\n",
              "      (norm2): LayerNormalization()\n",
              "      (feed_forward): feedForwardNN(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELUActivation()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (11): TransformerArchitect(\n",
              "      (multihead_attention): MultiHeadAttention(\n",
              "        (W_queries): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_keys): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_values): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
              "      (norm1): LayerNormalization()\n",
              "      (norm2): LayerNormalization()\n",
              "      (feed_forward): feedForwardNN(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELUActivation()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNormalization()\n",
              "  (output_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = predict_next_token(\n",
        "    model,\n",
        "    encoded_tensor,\n",
        "    max_new_tokens=10,\n",
        "    context_size=GPT_CONFIGURATION_PARAMS[\"context_length\"]\n",
        ")"
      ],
      "metadata": {
        "id": "grMjMs0QsYVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(output)"
      ],
      "metadata": {
        "id": "22wtwCtds892",
        "outputId": "23b3e9c5-9a3f-44a4-e9ab-216dc9fbd567",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[10814,   612, 16806, 24906, 27018,  7283, 48443, 26012, 16560, 44407,\n",
            "         34178, 12156]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decode_text = tokenizer.decode(output.squeeze(0).tolist())\n",
        "print(decode_text)"
      ],
      "metadata": {
        "id": "pYhTUVCis_4j",
        "outputId": "e2e2de1f-f572-4759-f635-4b95dd59cf89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hey there Applic HER Feature IT!/ Brigade incorporatedheartedly LIKEDep\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4gxILcm1tMew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Loss function"
      ],
      "metadata": {
        "id": "2VdGkW7t_TOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "T5R3WDAGB8eG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTArchitecture(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.embedding_layer = nn.Embedding(cfg['vocab_size'], cfg['emb_dim'])\n",
        "        self.pos_emb_layer = nn.Embedding(cfg['context_length'], cfg['emb_dim'])\n",
        "        self.drop_emb = nn.Dropout(cfg['dropout'])\n",
        "\n",
        "        self.transformer_blocks = nn.Sequential( *[TransformerArchitect(cfg) for _ in range(cfg['n_layers'])])\n",
        "        self.final_norm = LayerNormalization(cfg['emb_dim'])\n",
        "        self.output_head = nn.Linear(\n",
        "            cfg['emb_dim'], cfg['vocab_size'], bias=False\n",
        "        )\n",
        "\n",
        "    def forward(self, id_idx):\n",
        "        batch_size, seq_len = id_idx.shape\n",
        "        token_emb = self.embedding_layer(id_idx)\n",
        "        pos_emb = self.pos_emb_layer(torch.arange(seq_len, device=id_idx.device))\n",
        "        x = token_emb + pos_emb\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.transformer_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.output_head(x)\n",
        "        return logits\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_wFfiUv-_V7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,   # Vocabulary size\n",
        "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
        "    \"emb_dim\": 768,        # Embedding dimension\n",
        "    \"n_heads\": 12,         # Number of attention heads\n",
        "    \"n_layers\": 12,        # Number of layers\n",
        "    \"drop_rate\": 0.1,      # Dropout rate\n",
        "    \"qkv_bias\": False      # Query-key-value bias\n",
        "}\n"
      ],
      "metadata": {
        "id": "anqYll9DB7A0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "model = GPTArchitecture(GPT_CONFIG_124M)"
      ],
      "metadata": {
        "id": "miSA2OL-C23l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Qmk9901Dzwi",
        "outputId": "22507726-3ac9-4476-abc5-b47063b980b9",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTArchitecture(\n",
              "  (embedding_layer): Embedding(50257, 768)\n",
              "  (pos_emb_layer): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (transformer_blocks): Sequential(\n",
              "    (0): TransformerArchitect(\n",
              "      (multihead_attention): MultiHeadAttention(\n",
              "        (W_queries): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_keys): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_values): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
              "      (norm1): LayerNormalization()\n",
              "      (norm2): LayerNormalization()\n",
              "      (feed_forward): feedForwardNN(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELUActivation()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (1): TransformerArchitect(\n",
              "      (multihead_attention): MultiHeadAttention(\n",
              "        (W_queries): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_keys): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_values): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
              "      (norm1): LayerNormalization()\n",
              "      (norm2): LayerNormalization()\n",
              "      (feed_forward): feedForwardNN(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELUActivation()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (2): TransformerArchitect(\n",
              "      (multihead_attention): MultiHeadAttention(\n",
              "        (W_queries): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_keys): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_values): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
              "      (norm1): LayerNormalization()\n",
              "      (norm2): LayerNormalization()\n",
              "      (feed_forward): feedForwardNN(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELUActivation()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (3): TransformerArchitect(\n",
              "      (multihead_attention): MultiHeadAttention(\n",
              "        (W_queries): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_keys): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_values): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
              "      (norm1): LayerNormalization()\n",
              "      (norm2): LayerNormalization()\n",
              "      (feed_forward): feedForwardNN(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELUActivation()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (4): TransformerArchitect(\n",
              "      (multihead_attention): MultiHeadAttention(\n",
              "        (W_queries): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_keys): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_values): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
              "      (norm1): LayerNormalization()\n",
              "      (norm2): LayerNormalization()\n",
              "      (feed_forward): feedForwardNN(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELUActivation()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (5): TransformerArchitect(\n",
              "      (multihead_attention): MultiHeadAttention(\n",
              "        (W_queries): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_keys): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_values): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
              "      (norm1): LayerNormalization()\n",
              "      (norm2): LayerNormalization()\n",
              "      (feed_forward): feedForwardNN(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELUActivation()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (6): TransformerArchitect(\n",
              "      (multihead_attention): MultiHeadAttention(\n",
              "        (W_queries): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_keys): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_values): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
              "      (norm1): LayerNormalization()\n",
              "      (norm2): LayerNormalization()\n",
              "      (feed_forward): feedForwardNN(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELUActivation()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (7): TransformerArchitect(\n",
              "      (multihead_attention): MultiHeadAttention(\n",
              "        (W_queries): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_keys): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_values): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
              "      (norm1): LayerNormalization()\n",
              "      (norm2): LayerNormalization()\n",
              "      (feed_forward): feedForwardNN(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELUActivation()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (8): TransformerArchitect(\n",
              "      (multihead_attention): MultiHeadAttention(\n",
              "        (W_queries): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_keys): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_values): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
              "      (norm1): LayerNormalization()\n",
              "      (norm2): LayerNormalization()\n",
              "      (feed_forward): feedForwardNN(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELUActivation()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (9): TransformerArchitect(\n",
              "      (multihead_attention): MultiHeadAttention(\n",
              "        (W_queries): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_keys): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_values): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
              "      (norm1): LayerNormalization()\n",
              "      (norm2): LayerNormalization()\n",
              "      (feed_forward): feedForwardNN(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELUActivation()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (10): TransformerArchitect(\n",
              "      (multihead_attention): MultiHeadAttention(\n",
              "        (W_queries): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_keys): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_values): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
              "      (norm1): LayerNormalization()\n",
              "      (norm2): LayerNormalization()\n",
              "      (feed_forward): feedForwardNN(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELUActivation()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (11): TransformerArchitect(\n",
              "      (multihead_attention): MultiHeadAttention(\n",
              "        (W_queries): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_keys): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_values): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
              "      (norm1): LayerNormalization()\n",
              "      (norm2): LayerNormalization()\n",
              "      (feed_forward): feedForwardNN(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELUActivation()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNormalization()\n",
              "  (output_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "def text_to_token_id(tokenizer, text):\n",
        "\n",
        "    token_ids = tokenizer.encode(text)\n",
        "    return torch.tensor(token_ids).unsqueeze(0)\n",
        "\n",
        "def token_ids_to_text(tokenizer, token_ids):\n",
        "    texts = token_ids.squeeze(0)\n",
        "    return tokenizer.decode(texts.tolist())\n",
        "\n"
      ],
      "metadata": {
        "id": "IyXG0yG2D22W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_context = \"Every effort moves you\"\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "id": "6gWbakMGFDug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_ids = predict_next_token(model,\n",
        "                               text_to_token_id(tokenizer, start_context),\n",
        "                               max_new_tokens=10,\n",
        "                               context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        "                               )"
      ],
      "metadata": {
        "id": "r7vIPvPAFIsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(token_ids_to_text(tokenizer, token_ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aujOSMvzFuIu",
        "outputId": "3ac1e588-730d-4610-ca1f-102b18648e62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Every effort moves you rentingetic minion mobilized Macicone warrantyuler respirmediated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculating text generation loss: cross-entropy and perplexity"
      ],
      "metadata": {
        "id": "HBtXs06fF9f5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
        "                       [40,    1107, 588]])   #  \"I really like\"]\n",
        "\n",
        "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
        "                        [1107,  588, 11311]]) #  \" really like chocolate\"]"
      ],
      "metadata": {
        "id": "wM1WQ_JoGF7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    logits = model(inputs)\n",
        "\n",
        "probas = torch.softmax(logits, dim=-1) # Probability of each token in vocabulary\n",
        "print(probas.shape) # Shape: (batch_size, num_tokens, vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3wuEDZqGlyh",
        "outputId": "ac78374c-b067-4957-b371-c5fba0c67a28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 50257])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
        "print(\"Token IDs:\\n\", token_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-4PTB4kHuLP",
        "outputId": "49bafc0b-c89f-4f14-e65d-4d4ce451f316"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token IDs:\n",
            " tensor([[[36195],\n",
            "         [16031],\n",
            "         [42826]],\n",
            "\n",
            "        [[14212],\n",
            "         [ 7822],\n",
            "         [38509]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Targets batch 1: {token_ids_to_text(tokenizer, targets[0])}\")\n",
        "print(f\"Outputs batch 1: {token_ids_to_text(tokenizer, token_ids[0].flatten())}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRk4dnlGLedk",
        "outputId": "23f0ef41-3122-41e1-c5a9-01b22660587f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Targets batch 1:  effort moves you\n",
            "Outputs batch 1: lif savesNetflix\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0roo6GG7Lf6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLM Performance on real dataset"
      ],
      "metadata": {
        "id": "DtMhYAE2-jjV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reading the file\n",
        "with open('/content/sample_data/the-verdict.txt', 'r') as f:\n",
        "    text_data = f.read()"
      ],
      "metadata": {
        "id": "ndcbX0U7-nXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_data[:99])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ld6I4PKEfyN",
        "outputId": "458136e3-3413-4ec5-c2f5-4863d8c10f9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_characters = len(text_data)\n",
        "totak_tokens = len(tokenizer.encode(text_data))"
      ],
      "metadata": {
        "id": "eR0qoc2BElFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "totak_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMojHYdPE53Q",
        "outputId": "eb4f1f36-936a-49d7-d77f-bdd69d8e8414"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5145"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we will use byte-pair encoding\n",
        "# we will split dataset into train and val and for that, we will use dataLoader\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class GPT_Dataset(Dataset):\n",
        "\n",
        "    def __init__(self, text, tokenizer, max_length, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        token_ids = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "        for i in range(0, len(token_ids)-max_length, stride):\n",
        "              input_chunk = token_ids[i: i+max_length]\n",
        "              target_chunk = token_ids[i+1 : i+1+max_length]\n",
        "              self.input_ids.append(torch.tensor(input_chunk))\n",
        "              self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.input_ids[index], self.target_ids[index]\n",
        "\n"
      ],
      "metadata": {
        "id": "msh3RRuZE9MN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
        "                         stride=128, shuffle=True, drop_last=True,\n",
        "                         num_workers=0):\n",
        "\n",
        "    # Initialize the tokenizer\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "    # Create dataset\n",
        "    dataset = GPT_Dataset(txt, tokenizer, max_length, stride)\n",
        "\n",
        "    # Create dataloader\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        drop_last=drop_last,\n",
        "        num_workers=num_workers\n",
        "    )\n",
        "\n",
        "    return dataloader"
      ],
      "metadata": {
        "id": "H_fITeozKKM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,   # Vocabulary size\n",
        "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
        "    \"emb_dim\": 768,        # Embedding dimension\n",
        "    \"n_heads\": 12,         # Number of attention heads\n",
        "    \"n_layers\": 12,        # Number of layers\n",
        "    \"dropout\": 0.1,      # Dropout rate\n",
        "    \"qkv_bias\": False      # Query-key-value bias\n",
        "}\n"
      ],
      "metadata": {
        "id": "IkC_xmtDLQ5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating batches\n",
        "split_ratio = 0.9\n",
        "split_token = int(split_ratio * len(text_data))\n",
        "train_data = text_data[:split_token]\n",
        "val_data = text_data[split_token:]\n",
        "\n",
        "train_batch = create_dataloader_v1(\n",
        "    train_data,\n",
        "    2,\n",
        "    GPT_CONFIG_124M[\"context_length\"],\n",
        "    GPT_CONFIG_124M[\"context_length\"],\n",
        "    True,\n",
        "    True,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "val_batch = create_dataloader_v1(\n",
        "    val_data,\n",
        "    2,\n",
        "    GPT_CONFIG_124M[\"context_length\"],\n",
        "    GPT_CONFIG_124M[\"context_length\"],\n",
        "    True,\n",
        "    True,\n",
        "    num_workers=0\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "EI1VoHzQLTga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tokens = 0\n",
        "for input_batch, target_batch in train_batch:\n",
        "    train_tokens += input_batch.numel()\n",
        "\n",
        "val_tokens = 0\n",
        "for input_batch, target_batch in val_batch:\n",
        "    val_tokens += input_batch.numel()\n",
        "\n",
        "print(\"Training tokens:\", train_tokens)\n",
        "print(\"Validation tokens:\", val_tokens)\n",
        "print(\"All tokens:\", train_tokens + val_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ue2mmvS9Peu_",
        "outputId": "f22b134d-5e6f-4e3a-c281-dd34eba323b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training tokens: 4608\n",
            "Validation tokens: 512\n",
            "All tokens: 5120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)\n",
        "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
        "    return loss\n",
        "\n",
        "\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        # Reduce the number of batches to match the total number of batches in the data loader\n",
        "        # if num_batches exceeds the number of batches in the data loader\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches"
      ],
      "metadata": {
        "id": "cgfpJaPePUhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "torch.manual_seed(123) # For reproducibility due to the shuffling in the data loader\n",
        "\n",
        "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
        "    train_loss = calc_loss_loader(train_batch, model, device)\n",
        "    val_loss = calc_loss_loader(val_batch, model, device)\n",
        "\n",
        "print(\"Training loss:\", train_loss)\n",
        "print(\"Validation loss:\", val_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "L9qJ19B3VYcH",
        "outputId": "78bca305-2fed-476f-c89c-e734070b85c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'calc_loss_loader' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1116199545.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Disable gradient tracking for efficiency because we are not training, yet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_loss_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_loss_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'calc_loss_loader' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "pGaMQC_VDEXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLM Pre-training loop"
      ],
      "metadata": {
        "id": "-6SEJsrWYLey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# here, we will try to minimize loss function as much as possible\n",
        "# so, output as close to target"
      ],
      "metadata": {
        "id": "vrmGwF3EYPUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # backward pass -> allows to calculate gradient of the loss, which update the model weights and parameters\n",
        " # we find loss gradients --> loss.backward()\n"
      ],
      "metadata": {
        "id": "BlOzM8TSYZ1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_training_simple_version(model, train_loader, val_loader, optimizer\n",
        "                                  , device, num_epochs, eval_freq, eval_iter, start_context, tokenizer):\n",
        "    train_losses, val_losses, track_tokens_seen = [],[],[]\n",
        "    tokens_seen, global_step = 0,-1\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            tokens_seen += input_batch.numel() #total no of elements in input_batch\n",
        "            global_step += 1\n",
        "\n",
        "\n",
        "            # evaluation step\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                track_tokens_seen.append(tokens_seen)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # Print a sample text after each epoch\n",
        "        generate_and_print_sample(\n",
        "            model, tokenizer, device, start_context\n",
        "        )\n",
        "\n",
        "    return train_losses, val_losses, track_tokens_seen"
      ],
      "metadata": {
        "id": "PBm964oIZioD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss"
      ],
      "metadata": {
        "id": "an1vCiOBnccA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        "    model.eval()\n",
        "    context_size = model.pos_emb_layer.weight.shape[0]\n",
        "    encoded = text_to_token_id(tokenizer, start_context).to(device)\n",
        "    with torch.no_grad():\n",
        "        token_ids = predict_next_token(\n",
        "            model=model, idx=encoded,\n",
        "            max_new_tokens=50, context_size=context_size\n",
        "        )\n",
        "    decoded_text = token_ids_to_text(tokenizer, token_ids)\n",
        "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
        "    model.train()"
      ],
      "metadata": {
        "id": "4cUE4w8BneT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Note:\n",
        "# Uncomment the following code to calculate the execution time\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = GPTArchitecture(GPT_CONFIG_124M)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 10\n",
        "train_losses, val_losses, tokens_seen = model_training_simple_version(\n",
        "    model, train_batch, val_batch, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
        "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "# Note:\n",
        "# Uncomment the following code to show the execution time\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJbyWL63nfxc",
        "outputId": "fea45207-8fb8-4e0b-b6c7-3bb5846d64d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 9.778, Val loss 9.927\n",
            "Ep 1 (Step 000005): Train loss 8.077, Val loss 8.337\n",
            "Every effort moves you,,,,,,,,,,,,,,.                                   \n",
            "Ep 2 (Step 000010): Train loss 6.757, Val loss 7.041\n",
            "Ep 2 (Step 000015): Train loss 6.100, Val loss 6.597\n",
            "Every effort moves you, the,, the,,,,,,,,,.                                   \n",
            "Ep 3 (Step 000020): Train loss 5.831, Val loss 6.642\n",
            "Ep 3 (Step 000025): Train loss 5.123, Val loss 6.362\n",
            "Every effort moves you of theisburn to the picture to the to the pictureburn, and I had to the picture to the picture to have of the picture. I had been the picture to the my to the picture to the pictureburn's of the pictureburn,\n",
            "Ep 4 (Step 000030): Train loss 5.049, Val loss 6.271\n",
            "Ep 4 (Step 000035): Train loss 4.704, Val loss 6.240\n",
            "Every effort moves you know; and my dear was not to have to have to have to have my painting, and I was, and he was not to have of the pictureburn, and he was his pictures, and he was, and he was, and he was\n",
            "Ep 5 (Step 000040): Train loss 4.678, Val loss 6.278\n",
            "Every effort moves you know it was.                                              \n",
            "Ep 6 (Step 000045): Train loss 4.084, Val loss 6.131\n",
            "Ep 6 (Step 000050): Train loss 3.302, Val loss 6.166\n",
            "Every effort moves you know it was not that he was not to the fact-chairs. Gisburn's an--his--and here are the Riv to the end of the fact that he had been the end it, and I had been the fact, I had\n",
            "Ep 7 (Step 000055): Train loss 3.029, Val loss 6.132\n",
            "Ep 7 (Step 000060): Train loss 2.681, Val loss 6.200\n",
            "Every effort moves you know it was not that I felt.  \"I had been.                                   \n",
            "Ep 8 (Step 000065): Train loss 2.369, Val loss 6.190\n",
            "Ep 8 (Step 000070): Train loss 2.013, Val loss 6.217\n",
            "Every effort moves you know,\" was not that my hostess was \"I looked up his last word. Gisburn's an!     \"Oh, and I was a little him--and I was a little a little the room, I was\n",
            "Ep 9 (Step 000075): Train loss 1.555, Val loss 6.213\n",
            "Ep 9 (Step 000080): Train loss 1.129, Val loss 6.239\n",
            "Every effort moves you know,\" was not that my hostess was \"interesting\": on the last word. Gisburn's an!     \"Oh, and I had been_ his pictures--the quality of Jack's \"There were days when I\n",
            "Ep 10 (Step 000085): Train loss 1.065, Val loss 6.327\n",
            "Every effort moves you know,\" was one of the picture for nothing--I told Mrs.  \"Once, I was, one longed to cry out: \"Be dissatisfied with your leisure!\" as once one had longed to say: \"Be dissatisfied with your\n",
            "Training completed in 23.19 minutes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YGOLKGH98WcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model with Temperature and Top_K Sampling"
      ],
      "metadata": {
        "id": "08RZI27q1XI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax_with_temp(logits, temp):\n",
        "    scaled_logits = logits / temp\n",
        "    return torch.softmax(scaled_logits, dim=0)\n"
      ],
      "metadata": {
        "id": "FqZvycf81bf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # torch.topk(logits, top_k_number) -> returns top k logits, and their positions"
      ],
      "metadata": {
        "id": "PHWNprDA2AjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "vuPViHpZ-lkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(model, idx, max_new_tokens, context_size, temperature=1.0, top_k=None, eos_id=None):\n",
        "    for _ in range(max_new_tokens):\n",
        "        # Crop idx to the last context_size tokens to respect context window\n",
        "        idxs_cond = idx[:, -context_size:]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = model(idxs_cond)\n",
        "\n",
        "        # Focus on the last token's logits\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # Apply top-k filtering\n",
        "        if top_k is not None:\n",
        "            v, _ = torch.topk(logits, min(top_k, logits.size(-1))) # Ensure k is not larger than vocab size\n",
        "            logits[logits < v[:, [-1]]] = float('-inf') # Set smaller logits to -inf\n",
        "\n",
        "        # Apply temperature scaling\n",
        "        if temperature != 1.0:\n",
        "            logits = logits / temperature\n",
        "\n",
        "        probas = torch.softmax(logits, dim=-1)\n",
        "        idx_next = torch.multinomial(probas, num_samples=1) # Sample next token\n",
        "\n",
        "        # Check for end-of-sequence token\n",
        "        if eos_id is not None and (idx_next == eos_id).all():\n",
        "            break\n",
        "\n",
        "        idx = torch.cat((idx, idx_next), dim=1) # Append the sampled token\n",
        "\n",
        "    return idx"
      ],
      "metadata": {
        "id": "Cfp_SCAQ9HVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EC6GzY9wAQ6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downloading OpenAI Weights"
      ],
      "metadata": {
        "id": "uwC8ccoe3XLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests  # Make sure requests is installed\n",
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "CmOYFN943eEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_and_load_gpt2(model_size, models_dir):\n",
        "    # Validate model size\n",
        "    allowed_sizes = (\"124M\", \"355M\", \"774M\", \"1558M\")\n",
        "    if model_size not in allowed_sizes:\n",
        "        raise ValueError(f\"Model size not in {allowed_sizes}\")\n",
        "\n",
        "    # Define paths\n",
        "    model_dir = os.path.join(models_dir, model_size)\n",
        "    base_url = \"https://openaipublic.blob.core.windows.net/gpt-2/models\"\n",
        "    filenames = [\n",
        "        \"checkpoint\", \"encoder.json\", \"hparams.json\",\n",
        "        \"model.ckpt.data-00000-of-00001\", \"model.ckpt.index\",\n",
        "        \"model.ckpt.meta\", \"vocab.bpe\"\n",
        "    ]\n",
        "\n",
        "    # Download files\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "    for filename in filenames:\n",
        "        file_url = os.path.join(base_url, model_size, filename)\n",
        "        file_path = os.path.join(model_dir, filename)\n",
        "        download_file(file_url, file_path)\n",
        "\n",
        "    ## We have reached here until now ---> we have downloaded the files on our local machine.\n",
        "\n",
        "    # Load settings and params\n",
        "    tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n",
        "    settings = json.load(open(os.path.join(model_dir, \"hparams.json\")))\n",
        "    params = load_gpt2_params_from_tf_ckpt(tf_ckpt_path, settings)\n",
        "\n",
        "    return settings, params\n",
        "\n",
        "def download_file(url, destination):\n",
        "    try:\n",
        "        # Send a GET request to download the file, disabling SSL verification\n",
        "        response = requests.get(url, stream=True, verify=False)\n",
        "\n",
        "        # Get the total file size from headers, defaulting to 0 if not present\n",
        "        file_size = int(response.headers.get(\"content-length\", 0))\n",
        "\n",
        "        # Check if file exists and has the same size\n",
        "        if os.path.exists(destination):\n",
        "            file_size_local = os.path.getsize(destination)\n",
        "            if file_size == file_size_local:\n",
        "                print(f\"File already exists and is up-to-date: {destination}\")\n",
        "                return\n",
        "\n",
        "        # Define the block size for reading the file\n",
        "        block_size = 1024  # 1 Kilobyte\n",
        "\n",
        "        # Initialize the progress bar with total file size\n",
        "        progress_bar_description = url.split(\"/\")[-1]  # Extract filename from URL\n",
        "        with tqdm(total=file_size, unit=\"iB\", unit_scale=True, desc=progress_bar_description) as progress_bar:\n",
        "            # Open the destination file in binary write mode\n",
        "            with open(destination, \"wb\") as file:\n",
        "                # Iterate over the file data in chunks\n",
        "                for chunk in response.iter_content(block_size):\n",
        "                    progress_bar.update(len(chunk))  # Update progress bar\n",
        "                    file.write(chunk)  # Write the chunk to the file\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error downloading the file: {e}\")\n",
        "        print(f\"Please check the URL: {url}\")\n",
        "\n",
        "def load_gpt2_params_from_tf_ckpt(ckpt_path, settings):\n",
        "    # Initialize parameters dictionary with empty blocks for each layer\n",
        "    params = {\"blocks\": [{} for _ in range(settings[\"n_layer\"])]}\n",
        "\n",
        "    # Iterate over each variable in the checkpoint\n",
        "    for name, _ in tf.train.list_variables(ckpt_path):\n",
        "        # Load the variable and remove singleton dimensions\n",
        "        variable_array = np.squeeze(tf.train.load_variable(ckpt_path, name))\n",
        "\n",
        "        # Process the variable name to extract relevant parts\n",
        "        variable_name_parts = name.split(\"/\")[1:]  # Skip the 'model/' prefix\n",
        "\n",
        "        # Identify the target dictionary for the variable\n",
        "        target_dict = params\n",
        "        if variable_name_parts[0].startswith(\"h\"):\n",
        "            layer_number = int(variable_name_parts[0][1:])\n",
        "            target_dict = params[\"blocks\"][layer_number]\n",
        "\n",
        "        # Recursively access or create nested dictionaries\n",
        "        for key in variable_name_parts[1:-1]:\n",
        "            target_dict = target_dict.setdefault(key, {})\n",
        "\n",
        "        # Assign the variable array to the last key\n",
        "        last_key = variable_name_parts[-1]\n",
        "        target_dict[last_key] = variable_array\n",
        "\n",
        "    return params"
      ],
      "metadata": {
        "id": "M4q26bpZ3fmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"/content/gpt2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7glBEi83rHG",
        "outputId": "e1e881bc-3777-4bfe-ebda-ed41df208bef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "checkpoint: 100%|| 77.0/77.0 [00:00<00:00, 114kiB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "encoder.json: 100%|| 1.04M/1.04M [00:00<00:00, 2.93MiB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "hparams.json: 100%|| 90.0/90.0 [00:00<00:00, 256kiB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "model.ckpt.data-00000-of-00001: 100%|| 498M/498M [00:52<00:00, 9.56MiB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "model.ckpt.index: 100%|| 5.21k/5.21k [00:00<00:00, 9.09MiB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "model.ckpt.meta: 100%|| 471k/471k [00:00<00:00, 3.31MiB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "vocab.bpe: 100%|| 456k/456k [00:00<00:00, 1.92MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Settings\", settings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9577hJah4dJX",
        "outputId": "9ae9ed0d-00b6-422f-af91-2c0e672f1a20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Settings {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Sk6_pJt33azn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "\n",
        "# Copy the base configuration and update with specific model settings\n",
        "model_name = \"gpt2-small (124M)\"  # Example model name\n",
        "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
        "NEW_CONFIG.update(model_configs[model_name])"
      ],
      "metadata": {
        "id": "KquPQ4Dj4mp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n",
        "gpt = GPTModel(NEW_CONFIG)\n",
        "gpt.eval();"
      ],
      "metadata": {
        "id": "bPrlwyhp7fB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def assign(left, right):\n",
        "    if left.shape != right.shape:\n",
        "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
        "    return torch.nn.Parameter(torch.tensor(right))"
      ],
      "metadata": {
        "id": "uT2Hqk4-791g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "import numpy as np\n",
        "\n",
        "def load_weights_into_gpt(gpt, params):\n",
        "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
        "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
        "\n",
        "    for b in range(len(params[\"blocks\"])):\n",
        "        q_w, k_w, v_w = np.split(\n",
        "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
        "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
        "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
        "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
        "\n",
        "        q_b, k_b, v_b = np.split(\n",
        "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
        "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
        "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
        "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
        "\n",
        "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.weight,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.bias,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
        "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        gpt.trf_blocks[b].norm1.scale = assign(\n",
        "            gpt.trf_blocks[b].norm1.scale,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm1.shift = assign(\n",
        "            gpt.trf_blocks[b].norm1.shift,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
        "        gpt.trf_blocks[b].norm2.scale = assign(\n",
        "            gpt.trf_blocks[b].norm2.scale,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm2.shift = assign(\n",
        "            gpt.trf_blocks[b].norm2.shift,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
        "\n",
        "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
        "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
        "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "2KvaRq2M8FNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_weights_into_gpt(gpt, params)\n",
        "gpt.to(device);"
      ],
      "metadata": {
        "id": "la_CEBQN9y5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        self.final_norm = LayerNormalization(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(\n",
        "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
        "        )\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "d4TXEY3V-eYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            dropout=cfg[\"drop_rate\"],\n",
        "            qkv_bias=cfg[\"qkv_bias\"])\n",
        "        self.ff = feedForwardNN(cfg)\n",
        "        self.norm1 = LayerNormalization(cfg[\"emb_dim\"])\n",
        "        self.norm2 = LayerNormalization(cfg[\"emb_dim\"])\n",
        "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Shortcut connection for attention block\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        # Shortcut connection for feed forward block\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        # 2*4*768\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "blC2PUg6_xWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert (d_out % num_heads == 0), \\\n",
        "            \"d_out must be divisible by num_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer(\n",
        "            \"mask\",\n",
        "            torch.triu(torch.ones(context_length, context_length),\n",
        "                       diagonal=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "\n",
        "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
        "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
        "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
        "\n",
        "        # Original mask truncated to the number of tokens and converted to boolean\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "        # Use the mask to fill attention scores\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
        "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec) # optional projection\n",
        "\n",
        "        return context_vec"
      ],
      "metadata": {
        "id": "FdvQ74hYCU1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "acbUNiESCVm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerArchitect(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(cfg[\"emb_dim\"], cfg[\"emb_dim\"], cfg[\"context_length\"], cfg[\"n_heads\"], cfg[\"qkv_bias\"], cfg[\"dropout\"])\n",
        "        self.dropout_layer = nn.Dropout(cfg[\"dropout\"])\n",
        "        self.norm1 = LayerNormalization(cfg[\"emb_dim\"])\n",
        "        self.norm2 = LayerNormalization(cfg[\"emb_dim\"])\n",
        "        self.feed_forward = feedForwardNN(cfg)\n",
        "\n",
        "    def forward(self, x):\n",
        "        og_input = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x)\n",
        "        x = self.dropout_layer(x)\n",
        "\n",
        "        x = x + og_input\n",
        "\n",
        "        og_input = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.feed_forward(x)\n",
        "        x = self.dropout_layer(x)\n",
        "        x = x + og_input\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "1JKwhc4jADn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTArchitecture(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.embedding_layer = nn.Embedding(cfg['vocab_size'], cfg['emb_dim'])\n",
        "        self.pos_emb_layer = nn.Embedding(cfg['context_length'], cfg['emb_dim'])\n",
        "        self.drop_emb = nn.Dropout(cfg['dropout'])\n",
        "\n",
        "        self.transformer_blocks = nn.Sequential( *[TransformerArchitect(cfg) for _ in range(cfg['n_layers'])])\n",
        "        self.final_norm = LayerNormalization(cfg['emb_dim'])\n",
        "        self.output_head = nn.Linear(\n",
        "            cfg['emb_dim'], cfg['vocab_size'], bias=False\n",
        "        )\n",
        "\n",
        "    def forward(self, id_idx):\n",
        "        batch_size, seq_len = id_idx.shape\n",
        "        token_emb = self.embedding_layer(id_idx)\n",
        "        pos_emb = self.pos_emb_layer(torch.arange(seq_len, device=id_idx.device))\n",
        "        x = token_emb + pos_emb\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.transformer_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.output_head(x)\n",
        "        return logits\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Yg97P7pt-qgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken"
      ],
      "metadata": {
        "id": "V7SddQvhDnq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "id": "ofelBWkSDpCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "token_ids = generate(\n",
        "    model=gpt,\n",
        "    idx=text_to_token_id(tokenizer, \"always thought Jack Gisburn\").to(device),\n",
        "    max_new_tokens=25,\n",
        "    context_size=NEW_CONFIG[\"context_length\"],\n",
        "    top_k=50,\n",
        "    temperature=1.5\n",
        ")"
      ],
      "metadata": {
        "id": "E1dX_6KnDJut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Output text:\\n\", token_ids_to_text(tokenizer, token_ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ewRBfiYEhuO",
        "outputId": "48a7d07e-e4be-4de6-f05e-b8ceea8afc64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " always thought Jack Gisburn, Jr. would make a great quarterback at QB this season. The Bills did not come on, but Gisburn would\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "discipline_quotes = generate(\n",
        "    model=gpt,\n",
        "    idx=text_to_token_id(tokenizer, \"Early to bed early to rise\").to(device),\n",
        "    max_new_tokens=30,\n",
        "    context_size=NEW_CONFIG[\"context_length\"],\n",
        "    top_k=50,\n",
        "    temperature=0.8\n",
        ")\n",
        "\n",
        "print(\"Output text:\\n\", token_ids_to_text(tokenizer, discipline_quotes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJJxZM8yEwwL",
        "outputId": "483eb8e9-28c0-4a10-ce2b-7c1867bcc980"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " Early to bed early to rise. It was almost always the same morning. It was very cold. The weather was always very bad. Our house was very cold. My husband wasn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"hi\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gE9VWBxtQrCu",
        "outputId": "50601f7c-8140-4e7d-dff7-00a92726f1f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "discipline_quotes = generate(\n",
        "    model=gpt,\n",
        "    idx=text_to_token_id(tokenizer, \"In a world where quantum kangaroos exist, they jump over particles and\").to(device),\n",
        "    max_new_tokens=30,\n",
        "    context_size=NEW_CONFIG[\"context_length\"],\n",
        "    top_k=50,\n",
        "    temperature=0.8\n",
        ")\n",
        "\n",
        "print(\"Output text:\\n\", token_ids_to_text(tokenizer, discipline_quotes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_revRGPMrDyi",
        "outputId": "8988d00e-4099-4ed9-e9de-8529413e303f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " In a world where quantum kangaroos exist, they jump over particles and cause waves in the real world so that they can be made to move.\n",
            "\n",
            "This is why quantum kangaroos have such profound properties.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "discipline_quotes = generate(\n",
        "    model=gpt,\n",
        "    idx=text_to_token_id(tokenizer, \"In a world where calendars breathe, people learn to\").to(device),\n",
        "    max_new_tokens=30,\n",
        "    context_size=NEW_CONFIG[\"context_length\"],\n",
        "    top_k=50,\n",
        "    temperature=0.8\n",
        ")\n",
        "\n",
        "print(\"Output text:\\n\", token_ids_to_text(tokenizer, discipline_quotes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHLWE8Cfrozv",
        "outputId": "2d4bcafe-ffd3-4652-db26-c0a027b404a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " In a world where calendars breathe, people learn to take things in stride. It's a whole different story than we all know.\n",
            "\n",
            "\"I think people should be interested in making the choices they\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(gpt.state_dict(), \"/content/gpt_model.pt\")"
      ],
      "metadata": {
        "id": "SVgm0sLJtOT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the whole model (architecture + weights)\n",
        "torch.save(gpt, \"/content/gpt2_124M_full_model.pt\")\n"
      ],
      "metadata": {
        "id": "sNHuOBRQuT69"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}